{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c763e6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "\n",
    "cfg = json.load(open('api_config.json'))\n",
    "openai.api_key = cfg['KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a618d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "EMBED_MAX_TOKEN_LENGTH = 8000\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    \n",
    "    # Cuts texts down to maximum token length\n",
    "    tokens = encoding.encode(text)\n",
    "    if len(tokens) > EMBED_MAX_TOKEN_LENGTH:\n",
    "        text = encoding.decode(tokens[:EMBED_MAX_TOKEN_LENGTH])\n",
    "    \n",
    "    return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']\n",
    "\n",
    "# Possibly give random sampling of titles to get context before classifying?\n",
    "def get_cluster_label(prompt, model=\"gpt-3.5-turbo\", role=\"system\"):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": role, \"content\": prompt},\n",
    "        ],\n",
    "        temperature=0.5\n",
    "    )\n",
    "    \n",
    "    return response\n",
    "\n",
    "LLM_MAX_TOKEN_LENGTH = 4000\n",
    "SUMAMRY_PROMPT = \"write a few bullet point synopsis about this article for technical readers: \"\n",
    "def get_bullet_summary(text, model=\"gpt-3.5-turbo\", role=\"system\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    \n",
    "    tokens = encoding.encode(text)\n",
    "    if len(tokens) > LLM_MAX_TOKEN_LENGTH:\n",
    "        text = encoding.decode(tokens[:LLM_MAX_TOKEN_LENGTH])\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": role, \"content\": SUMAMRY_PROMPT + text},\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77b9c42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/text_data.csv', sep='\\t')\n",
    "\n",
    "# Drops all empty text rows\n",
    "df = df[df['title'] != ' '].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96363137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.iloc()[0]['title_embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b38b1407",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('embed_data.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81a2ee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate title embeddings\n",
    "df['title_embedding'] = df['title'].apply(lambda x: get_embedding(x, model='text-embedding-ada-002'))\n",
    "df.to_csv('embed_data.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40a73eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text embeddings\n",
    "df['text_embedding'] = df['text'].apply(lambda x: get_embedding(x, model='text-embedding-ada-002'))\n",
    "df.to_csv('embed_data.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c855985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate bullet summaries\n",
    "df['summary'] = df['text'].apply(lambda x: get_bullet_summary(x))\n",
    "df.to_csv('embed_data.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f13cbeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "K-Means Clustering\n",
    "\"\"\"\n",
    "matrix = np.vstack(df['title_embedding'].to_list())\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "n_clusters = int(len(df['title']) / 5)\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters, init=\"k-means++\", random_state=42)\n",
    "kmeans.fit(matrix)\n",
    "labels = kmeans.labels_\n",
    "df[\"cluster\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa23d939",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Labels each cluster with a overall topic.\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_TEMPLATE = f'''I am going to give you a list of titles of similar articles about artificial intelligence.\n",
    "All of these will be discussing different aspects of AI, so get as specific as possible.\n",
    "I would like you to provide a short description of the group of articles and a few word label for the group.\n",
    "This label should refer to the domain where AI is being applied in the articles. Some examples are:\n",
    "\"AI in Law\", \"Facial Recognition\", \"Quantum Computing\", or \"AI in Culture and Art. \n",
    "\n",
    "Format your response like this:\n",
    "\n",
    "description: <short description>\n",
    "label: <one word label>\n",
    "\n",
    "here is the list of article titles: \n",
    "'''\n",
    "\n",
    "prompts = []\n",
    "\n",
    "for cluster_ind in df['cluster'].unique():\n",
    "    # Gets the subframe of a specific cluster.\n",
    "    c_df = df[df['cluster'] == cluster_ind]\n",
    "    \n",
    "    titles = []\n",
    "    for t in list(c_df['title']):\n",
    "        titles.append(t)\n",
    "        \n",
    "    \n",
    "    prompts.append(PROMPT_TEMPLATE + str(titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "56a704f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Query GPT for cluster labels based on titles.\n",
    "\"\"\"\n",
    "responses = []\n",
    "for prompt in prompts:\n",
    "    responses.append(get_cluster_label(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5de7b154",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a dictionary for cluster information.\n",
    "\"\"\"\n",
    "\n",
    "# ChatGPT generated function.\n",
    "def get_substring_between_strings(input_string, start_string, end_string):\n",
    "    start_index = input_string.find(start_string)\n",
    "    if start_index == -1:\n",
    "        return None  # Start string not found in the input string\n",
    "\n",
    "    end_index = input_string.find(end_string, start_index + len(start_string))\n",
    "    if end_index == -1:\n",
    "        return None  # End string not found in the input string\n",
    "\n",
    "    substring = input_string[start_index + len(start_string):end_index]\n",
    "    return substring\n",
    "\n",
    "cluster_labels = dict()\n",
    "\n",
    "for r, cluster_ind in zip(responses, df['cluster'].unique()):\n",
    "    response = r.choices[0].message.content\n",
    "    \n",
    "    description = get_substring_between_strings(response, 'description: ', 'label: ').replace(\"\\n\", \"\")\n",
    "    label = response.split('label: ')[1].replace(\"\\n\", \"\")\n",
    "    \n",
    "    cluster_labels[int(cluster_ind)] = {'label': label, 'desc': description}\n",
    "    \n",
    "with open('cluster_labels.json', 'w') as f:\n",
    "    json.dump(cluster_labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13ab9a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adds cluster data to the dataframe.\n",
    "\"\"\"\n",
    "\n",
    "cluster_labels = dict()\n",
    "with open ('cluster_labels.json', 'r') as f:\n",
    "    cluster_labels = json.load(f)\n",
    "\n",
    "df['cluster_info'] = df['cluster'].astype(str).map(cluster_labels)\n",
    "df['cluster_label'] = df['cluster_info'].apply(lambda x: x['label'])\n",
    "df['cluster_desc'] = df['cluster_info'].apply(lambda x: x['desc'])\n",
    "\n",
    "df.to_csv('cluster_data.csv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa44083",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_space",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
